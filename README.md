# **Summarize.**
A revamping of the Cloudera Fast Forward Labs Brief application showcasing updated methodology for extractive and abstractive text summarization. 

The primary output of this repository is the **Summarize.** application, a prototype user interface for automatic text summarization. It includes the ability to apply both abstractive and extractive summarization models on various types of documents, including Wikipedia articles, news articles, and fiction book chapters. 

TODO: SCREENSHOT

## **Summarize.** interface
Instructions are given both for general use (on a laptop, say), and for Cloudera CML and CDSW. We'll first describe what's here, then go through how to run everything.

### Structure
```
.
├── apps        # Small Streamlit application.
├── cml         # This folder contains scripts that facilitate the project launch on CML.
├── data        # This folder contains starter data.
├── models      # This folder contains a serialized neural extractive summarization model.
└── summa       # A small library of useful functions.
```
There are also `images` and `tests` directories that can be ignored. Let's examine each of the important folders in turn.

### apps
The application accompanying this project comes with a launcher script to assist launching an Application with CDSW/CML. To launch the application in another environment, see instructions below. 

### cml
This script facilitates the automated project setup on CML and is triggered by the declarative pipeline as defined in the `.project-metadata.yaml` file found in the project's root directory.

### summa
```
summa
├── models
│   ├── classic_extractive.py
│   └── neural_extractive.py
├── highlighting.py
├── st_model_wrappers.py
├── text_cleanup.py
├── wiki_processing.py
└── utils.py
```

This small library includes functionality to support the **Summarize.** application. 

### notebooks
notebooks
├── CreatingRedditDataset.ipynb
├── Wmap_Experiments.ipynb
└── Zmap_Experiments.ipynb
The Wmap_Experiments and Zmap_Experiments notebooks walk through analysis discussed in the accompanying Few-Shot Text Classification report and are intended for interactive learning purposes. These work best when run as a Colab (rather than as a Jupyter Notebook) to take advantage of free GPUs.

The CreatingRedditDataset notebook is included purely to document the steps taken when creating the Reddit dataset that we include with this module (located in the data/reddit directory.) It is not intended to be run directly.

Performing text classification in limited-labeled-data regimes
To go from a fresh clone of the repo to the final state, follow these instructions in order.

## Installation
The code and applications within were developed against Python 3.8.0., and are likely also to function with more recent versions of Python. 

To install dependencies, first create and activate a new virtual environment through your preferred means, then pip install from the requirements file. We recommend:

```
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
In CML or CDSW, no virtual env is necessary. Instead, inside a Python 3 session (with at least 2 vCPU / 4 GiB Memory), simply run
```
!pip3 install -r requirements.txt     # notice `pip3`, not `pip`
```


### Launch **Summarize.**
After installation, the **Summarize.** application can be launched locall

```
streamlit run apps/summarize-app.py 
```



## Deploying on CML
There are three ways to launch this project on CML:

* **From Prototype Catalog** - Navigate to the Prototype Catalog on a CML workspace, select the "Deep Learning for Question Answering" tile, click "Launch as Project", click "Configure Project"
* **As ML Prototype** - In a CML workspace, click "New Project", add a Project Name, select "ML Prototype" as the Initial Setup option, copy in the repo URL, click "Create Project", click "Configure Project"
* **Manual Setup** - In a CML workspace, click "New Project", add a Project Name, select "Git" as the Initial Setup option, copy in the repo URL, click "Create Project". Then, follow the installation instructions above.

## Additional information
### Tests
The fewshot module logic is partly covered by unittests. To run all tests, use:

python -m unittest discover
We recommend running tests before committing any major changes.

The end-to-end test (test_e2e.py) will not work if files generated by on-the-fly_text_classification.py have not been generated. (These files are checked in.)

### Formatting
We use black library to format code. It is required that new changes to the library conform to this style. To auto-format code, you can call:

./format_code.sh
